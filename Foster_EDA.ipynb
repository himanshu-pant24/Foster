{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "497c873d-41d7-414d-a2a9-9615d0653f5c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. \n",
    "\n",
    "# Introduction\n",
    "\n",
    "An exploratory data analysis on a dataset of internet of Things data that represents sensor measurements recorded from interior rooms of the building, and to make suggestions to the facilities managers based on the findings.\n",
    "\n",
    "### Question to be Answered\n",
    "\n",
    "1. Data Quality:  Does data has any duplicate values, missing values, outliers, or errors?\n",
    "2. Does data have any patterns, trends, or correlations?\n",
    "3. Where is the location of sensors in the floor?\n",
    "4. How does the internet of Things data vary across different sensors, and floors?\n",
    "5. Is there any possible factors that affect the internet of Things data, such as outdoor weather?\n",
    "\n",
    "### Assumptions\n",
    "1. \"Temperature at desk height\" is considered at \"Temperature\" for building operation goals, which has been calculated by subtracting 1.5Â°C from the given Ceiling Temperature. As it is not mentioned which Temperature to take.\n",
    "\n",
    "2. In some cases, work hours are assumed from 9 AM to 5 PM as it is also not mentioned.\n",
    "\n",
    "\n",
    "### New Columns/Features \n",
    "\n",
    "New Columns/Features is created for data exploration\n",
    "\n",
    "temp_c: Temperature at ceiling Hight. temp_c = temp (given temperature)\n",
    "\n",
    "temp_d: Temperature at desk Hight. temp_d = temp_c - 1.5\n",
    "\n",
    "Floor: Floor of the given sensor e.g. '3F'.\n",
    "\n",
    "sensor_id_floor_lon: Combination of 'sensor_id' and 'Floor' in long format e.g. 'ENKZYW001900_4F'.\n",
    "\n",
    "sensor_id_floor_sho: Combination of 'sensor_id' and 'Floor' in short format e.g. '1900_4F'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a74f43c-7df4-4c75-adcd-c74be5aaea52",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 2. Import all the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install pandas==1.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbcbaeb6-7650-48ec-b6c9-7f10faa71983",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from imageio.v3 import imread\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Methods/Functions for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_api(url):\n",
    "\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "\n",
    "        # Parse the JSON data\n",
    "        json_data = response.json()\n",
    "\n",
    "    else:\n",
    "        # If the request was unsuccessful, print an error message\n",
    "        print(\"Failed to retrieve data from the URL. Status code:\", response.status_code)\n",
    "        json_data = {}\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df_indoor_2,column_name):\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivot_df_indoor_2 = df_indoor_2.pivot_table(index='documentTime', columns='sensor_id_floor_sho', values=[column_name]).reset_index()\n",
    "\n",
    "    # Flatten the multi-index column names\n",
    "    pivot_df_indoor_2.columns = ['_'.join(col).strip() for col in pivot_df_indoor_2.columns.values]\n",
    "\n",
    "    # Drop the 'documentTime_' column as it might not be relevant for correlation\n",
    "    pivot_df_indoor_2 = pivot_df_indoor_2.drop(columns=['documentTime_'])\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = pivot_df_indoor_2.corr()\n",
    "        \n",
    "    return correlation_matrix\n",
    "\n",
    "def strong_correlation_list(correlation_matrix):\n",
    "    \n",
    "    # Create an empty dictionary to store correlated columns\n",
    "    correlated_columns = {}\n",
    "\n",
    "    # Loop through each column in the correlation matrix\n",
    "    for column in correlation_matrix.columns:\n",
    "        # Get the highly correlated columns (correlation > 0.5)\n",
    "        highly_correlated = correlation_matrix[column][correlation_matrix[column] > 0.5].sort_values(ascending=False)\n",
    "        # Exclude the current column itself\n",
    "        highly_correlated = highly_correlated.drop(column, errors='ignore')\n",
    "        # Add to the dictionary\n",
    "        correlated_columns[column] = highly_correlated\n",
    "\n",
    "    # Print the correlated columns for each column\n",
    "    for column, correlated_cols in correlated_columns.items():\n",
    "        print(f\"Highly correlated columns with '{column}':\")\n",
    "        print(correlated_cols)\n",
    "        print()\n",
    "\n",
    "def correlation_plot(correlation_matrix):\n",
    "\n",
    "    # Plot heatmap using Plotly\n",
    "    fig = px.imshow(correlation_matrix,\n",
    "                    labels=dict(color=\"Correlation\"),\n",
    "                    x=correlation_matrix.columns,\n",
    "                    y=correlation_matrix.columns,\n",
    "                    title=\"Correlation Heatmap of Columns\",\n",
    "                    color_continuous_scale='RdBu')\n",
    "\n",
    "    # Update layout to tilt x-axis labels\n",
    "    fig.update_layout(xaxis={'tickangle': 45})\n",
    "\n",
    "    # Update layout to increase height and width\n",
    "    fig.update_layout(height=600, width=800)\n",
    "\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indoor_combined_single_plot(df_indoor,column_name,threhold):\n",
    "    \n",
    "    # Plotly line plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Iterate over each unique type and plot its line\n",
    "    for type_val in df_indoor['sensor_id_floor_lon'].unique():\n",
    "        df_type = df_indoor[(df_indoor['sensor_id_floor_lon'] == type_val)]\n",
    "        fig.add_trace(go.Scatter(x=df_type['documentTime'], y=df_type[column_name], mode='lines', name=type_val))\n",
    "\n",
    "    # Add a flat dotted line of threhold\n",
    "    fig.add_trace(go.Scatter(x=[min(df_indoor['documentTime']), max(df_indoor['documentTime'])], y=[threhold, threhold],\n",
    "                             mode='lines', name='Threshold line', line=dict(dash='dot', color='black', width=2)))\n",
    "\n",
    "    if(column_name == 'temp_d'):\n",
    "        title_name = 'Line Plot of Desk Temperature by Sensor'\n",
    "    elif(column_name == 'humidity'):\n",
    "        title_name = 'Line Plot of Humidity by Sensor'\n",
    "    elif(column_name == 'co2'):\n",
    "        title_name = 'Line Plot of co2 by Sensor'\n",
    "        \n",
    "    # Update layout\n",
    "    fig.update_layout(title= title_name,\n",
    "                      xaxis_title='documentTime',\n",
    "                      yaxis_title= column_name)\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "def indoor_combined_different_floor_plot(df_indoor,column_name,threhold):\n",
    "\n",
    "    # Plotly line plot\n",
    "    fig = go.Figure()\n",
    "\n",
    "    subplot_title = ['3rd Floor', '4th Floor']\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=subplot_title)\n",
    "\n",
    "    df_indoor_3F = df_indoor[df_indoor['Floor']=='3F']\n",
    "    df_indoor_4F = df_indoor[df_indoor['Floor']=='4F']\n",
    "\n",
    "    # Iterate over each unique type and plot its line\n",
    "    for type_val in df_indoor_3F['sensor_id_floor_sho'].unique():\n",
    "        df_type = df_indoor[(df_indoor['sensor_id_floor_sho'] == type_val)]\n",
    "        fig.add_trace(go.Scatter(x=df_type['documentTime'], y=df_type[column_name], mode='lines', name=type_val), row=1, col=1)\n",
    "\n",
    "    # Add a flat dotted line of threhold\n",
    "    fig.add_trace(go.Scatter(x=[min(df_indoor['documentTime']), max(df_indoor['documentTime'])], y=[temp_threhold, temp_threhold],\n",
    "                                 mode='lines', name='Threshold', line=dict(dash='dot', color='black', width=2)),row=1, col=1)\n",
    "\n",
    "    # Iterate over each unique type and plot its line\n",
    "    for type_val in df_indoor_4F['sensor_id_floor_sho'].unique():\n",
    "        df_type = df_indoor[(df_indoor['sensor_id_floor_sho'] == type_val)]\n",
    "        fig.add_trace(go.Scatter(x=df_type['documentTime'], y=df_type[column_name], mode='lines', name=type_val), row=1, col=2)\n",
    "\n",
    "    # Add a flat dotted line of threhold\n",
    "    fig.add_trace(go.Scatter(x=[min(df_indoor['documentTime']), max(df_indoor['documentTime'])], y=[threhold, threhold],\n",
    "                                 mode='lines', name='Threshold', line=dict(dash='dot', color='black', width=2)),row=1, col=2)\n",
    "\n",
    "    \n",
    "    if(column_name == 'temp_d'):\n",
    "        title_name = 'Line Plot of Desk Temperature by Sensor'\n",
    "    elif(column_name == 'humidity'):\n",
    "        title_name = 'Line Plot of Humidity by Sensor'\n",
    "    elif(column_name == 'co2'):\n",
    "        title_name = 'Line Plot of co2 by Sensor'\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(title=title_name,\n",
    "                      xaxis_title='documentTime',\n",
    "                      yaxis_title= column_name,\n",
    "                     height = 500, width = 1000)\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n",
    "\n",
    "def sesonality(df_indoor_seasonality,column_name,duration):\n",
    "\n",
    "    # Extracting time\n",
    "    df_indoor_seasonality['time_5'] = df_indoor_seasonality['documentTime'].dt.strftime('%H:%M')\n",
    "\n",
    "    # Extracting date\n",
    "    df_indoor_seasonality['Date'] = df_indoor_seasonality['documentTime'].dt.date\n",
    "\n",
    "    ## Group by time_5 and sensor_id_floor_lon, calculate mean\n",
    "    df_mean = df_indoor_seasonality.groupby(['time_5', 'sensor_id_floor_lon']).mean().reset_index()\n",
    "\n",
    "    ## Group by date and sensor_id_floor_lon, calculate mean\n",
    "    df_mean_2 = df_indoor_seasonality.groupby(['Date', 'sensor_id_floor_lon']).mean().reset_index()\n",
    "\n",
    "    # Create subplots\n",
    "    fig = make_subplots(rows=2, cols=1, subplot_titles=(\"3rd Floor\", \"4th Floor\"))\n",
    "\n",
    "    if (duration == 'Date'):\n",
    "        title_name = 'Weekly Seasonality ' + column_name\n",
    "        df_rand1 = df_mean_2[df_mean_2['sensor_id_floor_lon'].str.endswith('3F')].copy()\n",
    "        df_rand2 = df_mean_2[df_mean_2['sensor_id_floor_lon'].str.endswith('4F')].copy()\n",
    "\n",
    "        # Highlighting weekends\n",
    "        weekends = df_mean_2['Date'][df_mean_2['Date'].apply(lambda x: x.weekday() >= 5)].unique()\n",
    "\n",
    "        for weekend in weekends:\n",
    "            fig.add_shape(\n",
    "                type=\"rect\",\n",
    "                x0=weekend,\n",
    "                y0=min(df_mean_2[column_name]),\n",
    "                x1=weekend + pd.Timedelta(days=1),\n",
    "                y1=max(df_mean_2[column_name]),\n",
    "                fillcolor=\"LightSkyBlue\",\n",
    "                opacity=0.3,\n",
    "                layer=\"below\",\n",
    "                line=dict(width=0),\n",
    "                row=1, col=1\n",
    "            )\n",
    "\n",
    "        for weekend in weekends:\n",
    "            fig.add_shape(\n",
    "                type=\"rect\",\n",
    "                x0=weekend,\n",
    "                y0=min(df_mean_2[column_name]),\n",
    "                x1=weekend + pd.Timedelta(days=1),\n",
    "                y1=max(df_mean_2[column_name]),\n",
    "                fillcolor=\"LightSkyBlue\",\n",
    "                opacity=0.3,\n",
    "                layer=\"below\",\n",
    "                line=dict(width=0),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "\n",
    "    elif(duration == 'time_5'):\n",
    "        title_name = 'Daily Seasonality ' + column_name\n",
    "        df_rand1 = df_mean[df_mean['sensor_id_floor_lon'].str.endswith('3F')].copy()\n",
    "        df_rand2 = df_mean[df_mean['sensor_id_floor_lon'].str.endswith('4F')].copy()\n",
    "\n",
    "    # Iterate over each unique type and plot its line\n",
    "    for type_val in df_rand1['sensor_id_floor_lon'].unique():\n",
    "        df_type = df_rand1[df_rand1['sensor_id_floor_lon'] == type_val]\n",
    "        fig.add_trace(go.Scatter(x=df_type[duration], y=df_type[column_name], mode='lines', name=type_val, showlegend=True), row=1, col=1)\n",
    "\n",
    "\n",
    "    # Iterate over each unique type and plot its line\n",
    "    for type_val in df_rand2['sensor_id_floor_lon'].unique():\n",
    "        df_type = df_rand2[df_rand2['sensor_id_floor_lon'] == type_val]\n",
    "        fig.add_trace(go.Scatter(x=df_type[duration], y=df_type[column_name], mode='lines', name=type_val,showlegend=True), row=2, col=1)\n",
    "\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title_name,\n",
    "        xaxis_title=duration,\n",
    "        yaxis_title=\"Mean Value\",\n",
    "        height = 800\n",
    "    )\n",
    "\n",
    "    # Show plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, group_column='sensor_id', based_column='temp_d', out_threshold=1.5,cond_threhold = 21, type='outlier'):\n",
    "    outliers = pd.DataFrame(columns=df.columns)\n",
    "    outliers1 = pd.DataFrame(columns=df.columns)\n",
    "    outliers2 = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    if(type=='outlier'):\n",
    "      for group, data in df.groupby(group_column):\n",
    "          q1 = np.percentile(data[based_column], 25)\n",
    "          q3 = np.percentile(data[based_column], 75)\n",
    "          iqr = q3 - q1\n",
    "          lower_bound = q1 - out_threshold * iqr\n",
    "          upper_bound = q3 + out_threshold * iqr\n",
    "          outlier_indices = (data[based_column] < lower_bound) | (data[based_column] > upper_bound)\n",
    "          #print(data[outlier_indices])\n",
    "          outliers = pd.concat([outliers, data[outlier_indices]])\n",
    "\n",
    "\n",
    "    elif(type=='condition'):\n",
    "      for group, data in df.groupby(group_column):\n",
    "        outlier_indices1 = (data[based_column] < cond_threhold)\n",
    "        outlier_indices2 = (data[based_column] > cond_threhold)\n",
    "        #print(data[outlier_indices])\n",
    "        outliers1 = pd.concat([outliers1, data[outlier_indices1]])\n",
    "        outliers2 = pd.concat([outliers2, data[outlier_indices2]])\n",
    "      \n",
    "      if(based_column=='co2'):\n",
    "        outliers=outliers2\n",
    "      else:\n",
    "        outliers=outliers1\n",
    "\n",
    "    # Extract date from rounded timestamp\n",
    "    outliers['date'] = outliers['documentTime'].dt.date\n",
    "\n",
    "    # Group by 'type_column' and date, count outliers for each sensor type for each day\n",
    "    outliers_count_per_sensor_per_day = outliers.groupby(['sensor_id', 'date']).size().reset_index(name='outliers_count')\n",
    "      \n",
    "    return outliers,outliers_count_per_sensor_per_day\n",
    "\n",
    "\n",
    "def outlier_plot(df, sensor_type):\n",
    "  df = outliers_count_per_sensor_per_day\n",
    "\n",
    "  # Create the figure object with subplots\n",
    "  fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"pie\"}, {\"type\": \"pie\"}]], horizontal_spacing=0.2)\n",
    "\n",
    "  # Add trace for sensor_id\n",
    "  fig.add_trace(\n",
    "      go.Pie(\n",
    "          labels=outliers_count_per_sensor_per_day[\"sensor_id\"],\n",
    "          values=outliers_count_per_sensor_per_day[\"outliers_count\"],\n",
    "          textinfo=\"label+value+percent\",\n",
    "          name=\"Sensor ID\",\n",
    "          showlegend=False  # Show legend for this trace\n",
    "      ),\n",
    "      row=1, col=1\n",
    "  )\n",
    "\n",
    "  # Add trace for date\n",
    "  fig.add_trace(\n",
    "      go.Pie(\n",
    "          labels=outliers_count_per_sensor_per_day[\"date\"],\n",
    "          values=outliers_count_per_sensor_per_day[\"outliers_count\"],\n",
    "          textinfo=\"label+value+percent\",\n",
    "          name=\"Date\",\n",
    "          showlegend=False  # Show legend for this trace\n",
    "      ),\n",
    "      row=1, col=2\n",
    "  )\n",
    "\n",
    "  # Add heading for the first subplot\n",
    "  fig.add_annotation(\n",
    "      x=0.15,\n",
    "      y=-0.2,\n",
    "      xref=\"paper\",\n",
    "      yref=\"paper\",\n",
    "      text=\"Outliers Count by Sensor ID\",\n",
    "      showarrow=False,\n",
    "      font=dict(\n",
    "          size=14,\n",
    "          color=\"black\"\n",
    "      )\n",
    "  )\n",
    "\n",
    "  # Add heading for the second subplot\n",
    "  fig.add_annotation(\n",
    "      x=0.9,\n",
    "      y=-0.2,\n",
    "      xref=\"paper\",\n",
    "      yref=\"paper\",\n",
    "      text=\"Outliers Count by Date\",\n",
    "      showarrow=False,\n",
    "      font=dict(\n",
    "          size=14,\n",
    "          color=\"black\"\n",
    "      )\n",
    "  )\n",
    "  title = sensor_type + \" Count\"\n",
    "  fig.update_layout(title_text=title, height=600, width=850)\n",
    "  fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gaps(df,duration):\n",
    "    \n",
    "    #Find the time difference between the consecutive dates\n",
    "    df['time_diff'] = df['documentTime'].diff()\n",
    "    \n",
    "    if(duration=='minutes'):\n",
    "    \n",
    "        #Find rows with date gaps greater than 5 minutes\n",
    "        gaps = df[df['time_diff'] > pd.Timedelta(minutes=15)]\n",
    "    \n",
    "    elif(duration=='hours'):\n",
    "\n",
    "        #Find rows with date gaps greater than 1 hour\n",
    "        gaps = df[df['time_diff'] > pd.Timedelta(hours=1)]\n",
    "        \n",
    "    if gaps.empty:\n",
    "        print(\"No gaps found\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Gaps found\")\n",
    "        for i in range(len(gaps)):\n",
    "            gap_end = gaps.iloc[i]['documentTime']\n",
    "            gap_start = df.iloc[df.index.get_loc(gaps.index[i])-1]['documentTime']\n",
    "            gap_length = gaps.iloc[i]['time_diff']\n",
    "            print(f\"Gap start: {gap_start} | Gap end: {gap_end} | Gap length: {gap_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot_overall(df,floor):\n",
    "    df=df[df['Floor']==floor].copy()\n",
    "\n",
    "\n",
    "    # Calculate percentage and actual count of each flag\n",
    "    flag_counts = df[['Flag_Temp', 'Flag_humidity', 'Flag_co2', 'Combined_Flag']].sum()\n",
    "    total_records = len(df)\n",
    "\n",
    "    # Calculate percentage\n",
    "    flag_percentages = flag_counts / total_records * 100\n",
    "\n",
    "    # Create a list to hold both actual count and percentage for each flag\n",
    "    flag_info = [(count, percentage) for count, percentage in zip(flag_counts, flag_percentages)]\n",
    "\n",
    "    # Plot using Plotly\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(x=['Temp', 'Humidity', 'CO2', 'Combined'],\n",
    "                         y=[info[1] for info in flag_info],  # Extracting percentages from flag_info list\n",
    "                         text=[f\"Count: {info[0]}<br>Percentage: {info[1]:.2f}%\" for info in flag_info],  # Adding text for hover\n",
    "                         marker_color=['blue', 'orange', 'green', 'red']))\n",
    "\n",
    "    title_name = 'Number of points crossing given condition of period = ' + str(total_records) + \" data points\"\n",
    "    \n",
    "    fig.update_layout(title=title_name,\n",
    "                      xaxis_title='Flags',\n",
    "                      yaxis_title='Percentage')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def incident_plot(df, display_type,floor):\n",
    "    \n",
    "    #sensor_type = 'temp_desk'\n",
    "    group_column='sensor_id'\n",
    "    #based_column='temp_d'\n",
    "\n",
    "    incidents = pd.DataFrame(columns=df.columns)\n",
    "    df=df[df['Floor']==floor].copy()\n",
    "\n",
    "    for group, data in df.groupby(group_column):\n",
    "\n",
    "        incidents_indices = (data['Combined_Flag'] == True)\n",
    "        incidents = pd.concat([incidents, data[incidents_indices]])\n",
    "\n",
    "    # Extract date from rounded timestamp\n",
    "    incidents['date'] = incidents['documentTime'].dt.date\n",
    "\n",
    "    # Group by 'type_column' and date, count outliers for each sensor type for each day\n",
    "    outliers_count_per_sensor_per_day = incidents.groupby(['sensor_id', 'date']).size().reset_index(name='outliers_count')\n",
    "    \n",
    "    fig = go.Figure()\n",
    "\n",
    "    if (display_type == \"sensor_id\"):\n",
    "        # Add trace for sensor_id\n",
    "        fig.add_trace(\n",
    "          go.Pie(\n",
    "              labels=outliers_count_per_sensor_per_day[\"sensor_id\"],\n",
    "              values=outliers_count_per_sensor_per_day[\"outliers_count\"],\n",
    "              textinfo=\"label+value+percent\",\n",
    "              name=\"Sensor ID\",\n",
    "              showlegend=False  # Show legend for this trace\n",
    "          )\n",
    "        )\n",
    "    \n",
    "    elif (display_type == \"date\"):\n",
    "    # Add trace for sensor_id\n",
    "        fig.add_trace(\n",
    "          go.Pie(\n",
    "              labels=outliers_count_per_sensor_per_day[\"date\"],\n",
    "              values=outliers_count_per_sensor_per_day[\"outliers_count\"],\n",
    "              textinfo=\"label+value+percent\",\n",
    "              name=\"Sensor ID\",\n",
    "              showlegend=False  # Show legend for this trace\n",
    "          )\n",
    "        )\n",
    "            \n",
    "    \n",
    "    title_name = \"No of incident by \" + display_type\n",
    "    fig.update_layout(title_text=title_name, height=600, width=850)\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2907001-a17e-4c23-9983-3251f5ae2a44",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 3. Data Ingestion \n",
    "\n",
    "### Read the JSON files from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "220bcb31-ffc7-4f98-9a2c-9667b275b777",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# URL of the indoor JSON file\n",
    "url_indoor = \"https://fpardrecruiting002st.z33.web.core.windows.net/CodeEvaluation/DataScientist/iaq.json\"\n",
    "\n",
    "# URL of the outdoor JSON file\n",
    "url_outdoor = \"https://fpardrecruiting002st.z33.web.core.windows.net/CodeEvaluation/DataScientist/oaq.json\"\n",
    "\n",
    "# URL of the Sensor location JSON file\n",
    "url_sensor_location = \"https://fpardrecruiting002st.z33.web.core.windows.net/CodeEvaluation/DataScientist/floors.json\"\n",
    "\n",
    "json_data_indoor = json_api(url_indoor)\n",
    "json_data_outdoor = json_api(url_outdoor)\n",
    "json_data_sensor_location = json_api(url_sensor_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "525af03e-47e3-4f12-97a5-f5f08cf7424a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3.1 Convert the Data into pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6966a234-5f84-4ba7-891a-be30694f6745",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert JSON data to DataFrame\n",
    "df_indoor = pd.DataFrame(json_data_indoor)\n",
    "df_outdoor = pd.DataFrame(json_data_outdoor)\n",
    "df_s_location = pd.DataFrame(json_data_sensor_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56d2db96-02bf-4949-9e06-8056c4b49526",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# 4. Basic Exploration and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7608badc-9326-472d-aa43-c0b9a95f7069",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.1 Sensor location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fe03dc1-6b1d-43b7-be09-fc78bbef2fc7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_s_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10ffae25-0bf8-4016-9c96-215456368a6b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_s_location.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5d9e0ec-548b-4603-9c69-d0b2694b7c17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There is no missing data. The data has information of the coordinates of each sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34bbdf7d-0fa2-4173-a862-5dbffb6762c6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Plotting Sensor location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "686e274e-c15f-4107-8732-3f283f1cc235",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Storing the index of 3rd floor and 4th floor for access of data in the future\n",
    "index_H3F = df_s_location[df_s_location['id'] == 'H-3F'].index[0]\n",
    "index_H4F = df_s_location[df_s_location['id'] == 'H-4F'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b87d25e7-d4e6-4b87-86ef-94dca9eb021b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to store sensor group information\n",
    "sensor_group = {}\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in df_s_location.iterrows():\n",
    "\n",
    "    # Extract the sensors for the current row\n",
    "    sensors_info = row['sensors']\n",
    "    \n",
    "    # Format it into the desired dictionary format\n",
    "    key = row['id'][2:]  # Extracting '3F' from 'H-3F'\n",
    "    sensor_group[key] = [sensor['sensor_id'] for sensor in sensors_info]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3rd Floor sensor location plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c773673-154a-4dd1-888d-3e00ae31dec9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the points of 3rd Floor\n",
    "\n",
    "url = \"https://fpardrecruiting002st.z33.web.core.windows.net/CodeEvaluation/DataScientist/H-3F.png\"\n",
    "img = imread(url)\n",
    "\n",
    "# Get the width and height of the image\n",
    "width, height = df_s_location['image'][index_H3F]['width'], df_s_location['image'][index_H3F]['height']\n",
    "\n",
    "# Set the figure size to match the image size\n",
    "plt.figure(figsize=(width / 100, height / 100))  # Convert pixels to inches\n",
    "plt.imshow(img)\n",
    "#plt.axis('off') \n",
    "\n",
    "sensors_H3F = df_s_location['sensors'][index_H3F]\n",
    "\n",
    "# Extract x and y coordinates of sensor locations\n",
    "sensor_x = [sensor['location']['x'] for sensor in sensors_H3F]\n",
    "sensor_y = [sensor['location']['y'] for sensor in sensors_H3F]\n",
    "\n",
    "sensor_ids = [sensor['sensor_id'] for sensor in sensors_H3F]\n",
    "\n",
    "# Plot sensor locations on top of the image\n",
    "plt.scatter(sensor_x, sensor_y, color='red', marker='x')\n",
    "\n",
    "# Add sensor_id labels\n",
    "for i, txt in enumerate(sensor_ids):\n",
    "    plt.text(sensor_x[i], sensor_y[i], txt, fontsize=8, color='black', va='bottom', ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4th Floor sensor location plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "642e9457-4cb2-448f-8dbb-1f5ee9bf4d38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the points of 4th Floor\n",
    "\n",
    "url = \"https://fpardrecruiting002st.z33.web.core.windows.net/CodeEvaluation/DataScientist/H-4F.png\"\n",
    "img = imread(url)\n",
    "\n",
    "# Get the width and height of the image\n",
    "width, height = df_s_location['image'][index_H4F]['width'], df_s_location['image'][index_H3F]['height']\n",
    "\n",
    "# Set the figure size to match the image size\n",
    "plt.figure(figsize=(width / 100, height / 100))  # Convert pixels to inches\n",
    "plt.imshow(img)\n",
    "#plt.axis('off') \n",
    "\n",
    "sensors_H4F = df_s_location['sensors'][index_H4F]\n",
    "\n",
    "# Extract x and y coordinates of sensor locations\n",
    "sensor_x = [sensor['location']['x'] for sensor in sensors_H4F]\n",
    "sensor_y = [sensor['location']['y'] for sensor in sensors_H4F]\n",
    "\n",
    "sensor_ids = [sensor['sensor_id'] for sensor in sensors_H4F]\n",
    "\n",
    "# Plot sensor locations on top of the image\n",
    "plt.scatter(sensor_x, sensor_y, color='red', marker='x')\n",
    "\n",
    "# Add sensor_id labels\n",
    "for i, txt in enumerate(sensor_ids):\n",
    "    plt.text(sensor_x[i], sensor_y[i], txt, fontsize=8, color='black', va='bottom', ha='right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce59b461-6455-4d2d-8a92-a64222537b8d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4.2 Indoor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2daedc3c-f92d-42eb-a458-ff7474d7bf0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_indoor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "119fc40f-1296-4d95-8f28-9a0cb4b71fec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The data type of each column seems alright except 'documentTime'. There is no null values, however it could be possible than there are gaps in between 'documentTime'. For example, if we investigate sensor by sensor, we could find some time gaps which are greater than 5 mins as the data is suppose to come every 5 mins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating New columns and correcting data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac7e5eed-3505-4648-9fae-5f6ad4db62b4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Converting documentTime in datetime format\n",
    "df_indoor['documentTime'] = pd.to_datetime(df_indoor['documentTime'])\n",
    "\n",
    "# Sort the DataFrame by 'Timestamp' to ensure timestamps are in order\n",
    "df_indoor = df_indoor.sort_values(by='documentTime')\n",
    "\n",
    "#Restting the index and dropping 'index' column\n",
    "df_indoor = df_indoor.reset_index()\n",
    "df_indoor = df_indoor.drop(columns={'index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50115310-fb84-4585-b1c7-7ebb81c02a03",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Based on the information provided in the documnet, we are creating a two columns i.e. 'temp_c' and 'temp_d'. They will represent temperature at 'ceiling' height and 'desk' heigh respectively. Moreover, a column 'Floor' is also created to map each sensor to its floor which can gives us some insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c12942a6-3b79-42fc-93a3-c21064f6dc68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Renaming temp to temp_c for temperature at 'ceiling' height\n",
    "df_indoor = df_indoor.rename(columns={'temp':'temp_c'})\n",
    "\n",
    "# Renaming temp to temp_d for temperature at 'desk' height\n",
    "df_indoor['temp_d'] = df_indoor['temp_c']-1.5\n",
    "\n",
    "# Creting a column Floor' to map each sensor to its floor using sensor_group dictionary\n",
    "df_indoor['Floor'] = df_indoor['sensor_id'].map({t: floor for floor, types in sensor_group.items() for t in types})\n",
    "\n",
    "# Extract substring from 'sensor_id' column and concatenate with 'Floor' column\n",
    "df_indoor['sensor_id_floor_lon'] = df_indoor['sensor_id'] + '_' + df_indoor['Floor']\n",
    "df_indoor['sensor_id_floor_sho'] = df_indoor['sensor_id'].str[8:] + '_' + df_indoor['Floor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "44c0adcb-2516-4b97-8c82-8b4d3c1b337a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Finding Duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "419dec92-bd62-4398-9c4b-3e5448456be9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def duplicate_plot(duplicate_rows):\n",
    "  # Count the occurrences of each sensor type\n",
    "  duplicate_counts = duplicate_rows['sensor_id_floor_lon'].value_counts().reset_index()\n",
    "  duplicate_counts.columns = ['sensor_id_floor_lon', 'Count']\n",
    "\n",
    "  # Plotting the bar chart using Plotly\n",
    "  fig = px.bar(duplicate_counts, x='sensor_id_floor_lon', y='Count', \n",
    "              title='Count of Duplicate Rows for Each Sensor Type',\n",
    "              labels={'sensor_id_floor_lon': 'Sensor Type', 'Count': 'Count'},\n",
    "              color='sensor_id_floor_lon')\n",
    "\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eae0f25a-fcd7-4a48-af54-86b5f7a09141",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = df_indoor[df_indoor.duplicated()]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_plot(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b56e2cd2-43be-448f-8935-157670da0c4d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df_indoor = df_indoor.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the duplicate columns has been dropped, there could be some cases where for a 'sensor_id' multiple time stamps are available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66ac275d-19b8-4b2d-a9ce-4fd1660c7dc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Find duplicate rows in 'Time' column for each 'Type'\n",
    "duplicate_rows = df_indoor[df_indoor.duplicated(subset=['documentTime', 'sensor_id'], keep=False)]\n",
    "\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f7e51b3-1769-4f60-abd1-76a8d0a08d70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Finding Gaps in the data based of 'documentTime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bc40b0e-e779-4ec3-b45d-0947c8ef5f64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#removing warnings\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "#Storing all the sensors in sensors list \n",
    "sensors = df_indoor['sensor_id_floor_lon'].unique()\n",
    "\n",
    "#Finding gaps for each sensors\n",
    "for i in sensors:\n",
    "    print(i)\n",
    "    find_gaps(df_indoor[df_indoor['sensor_id_floor_lon']==i],'minutes')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Outdoor Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outdoor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = df_outdoor[df_outdoor.duplicated()]\n",
    "\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df_outdoor = df_outdoor.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows in 'documentTime' column to see if One time stamp has multiple entries.\n",
    "duplicate_rows = df_outdoor[df_outdoor.duplicated(subset=['documentTime'], keep='first')]\n",
    "\n",
    "len(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have 59 cases where there are multiple entries for one timestamp. It could be possible they belong to just the next time stamp. Since there is no clarity now, we'll be dropping those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping the first entry of each duplicate value\n",
    "df_outdoor.drop_duplicates(subset=['documentTime'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing 'documentTime' column to datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outdoor['documentTime'] = pd.to_datetime(df_outdoor['documentTime'])\n",
    "\n",
    "# Sort the DataFrame by 'Timestamp' to ensure timestamps are in order\n",
    "df_outdoor = df_outdoor.sort_values(by='documentTime')\n",
    "\n",
    "df_outdoor = df_outdoor.reset_index()\n",
    "\n",
    "df_outdoor = df_outdoor.drop(columns={'index'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look for gaps in 'documentTime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_gaps(df_outdoor,'hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'time_diff' column\n",
    "df_outdoor = df_outdoor.drop(columns={'time_diff'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outdoor.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all the outdoor features in a single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# \n",
    "fig.add_trace(go.Scatter(x=df_outdoor['documentTime'], y=df_outdoor['temperature'], mode='lines', name='temperature'))\n",
    "fig.add_trace(go.Scatter(x=df_outdoor['documentTime'], y=df_outdoor['humidity'], mode='lines', name='humidity'))\n",
    "fig.add_trace(go.Scatter(x=df_outdoor['documentTime'], y=df_outdoor['windSpeed'], mode='lines', name='windSpeed'))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Line Plot of Outdoor temperature and wind speed data',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title='temp')\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Humidity: The overall trend is flat. There have been a couple of dips e.g. Feb 6.\n",
    "\n",
    "Temperature: It has a sinusoidal sort of pattern. It kept increasing from the start till Feb 3. It started going downward and again started going upwards from 9-10 Feb.\n",
    "\n",
    "WindSpeed: Most of the data is missing and long flat lines. The data seems to be unreliable to use.\n",
    "\n",
    "Note: Please select the feature from the legend to analyze one feture at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. How well the Given conditions is maintained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Looking for rows which crosses the given conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of df_indoor dataframe\n",
    "df_indoor_2= df_indoor.copy()\n",
    "\n",
    "# Round timestamps to nearest 5 minutes\n",
    "df_indoor_2['documentTime'] = df_indoor_2['documentTime'].dt.round('5min')\n",
    "\n",
    "# Set seconds to 0\n",
    "df_indoor_2['documentTime'] = df_indoor_2['documentTime'].dt.floor('1min')\n",
    "\n",
    "# Create flags\n",
    "df_indoor_2['Flag_Temp'] = df_indoor_2['temp_d'] < 21\n",
    "df_indoor_2['Flag_humidity'] = df_indoor_2['humidity'] < 20\n",
    "df_indoor_2['Flag_co2'] = df_indoor_2['co2'] > 1000\n",
    "df_indoor_2['Combined_Flag']= df_indoor_2['Flag_Temp']|df_indoor_2['Flag_humidity']|df_indoor_2['Flag_co2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dataframe for working perios i.e. 9 to 5\n",
    "df_indoor_2_wh = df_indoor_2.copy()\n",
    "\n",
    "# Filter rows based on hour component of the timestamp\n",
    "df_indoor_2_wh = df_indoor_2_wh[(df_indoor_2_wh['documentTime'].dt.hour >= 9) & (df_indoor_2_wh['documentTime'].dt.hour <= 17)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the rows/data points which crosses the given conditions in 3rd Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor = '3F'\n",
    "bar_plot_overall(df_indoor_2,floor)\n",
    "bar_plot_overall(df_indoor_2_wh,floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature readings from the sensors contribute the most as far as crossing the limit is concerned in both 'Overall' and 'Working hours'. It is followed by CO2. Interestingly, all the points of CO2 are from assumed 'Working hours' i.e. 9-5. There is no case of Humidity as far as crossing the limit is concerned. Let's find out which sensors and Dates are contributing the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensors and Dates where values are crossing the operating conditions in 3rd Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_type = 'sensor_id'\n",
    "floor = '3F'\n",
    "incident_plot(df_indoor_2_wh, display_type, floor)\n",
    "\n",
    "display_type = 'date'\n",
    "floor = '3F'\n",
    "incident_plot(df_indoor_2_wh, display_type, floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the rows/data points which crosses the given conditions in 4th Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "floor = '4F'\n",
    "bar_plot_overall(df_indoor_2,floor)\n",
    "bar_plot_overall(df_indoor_2_wh,floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensors and Dates where values are crossing the operating conditions in 4th Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_type = 'sensor_id'\n",
    "floor = '4F'\n",
    "incident_plot(df_indoor_2_wh, display_type, floor)\n",
    "\n",
    "display_type = 'date'\n",
    "floor = '4F'\n",
    "incident_plot(df_indoor_2_wh, display_type, floor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Data Exploration - Indoor temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Combined Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Statistics of desk temperature for both floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "414d3ac3-c03d-4aa8-9464-22d1922cc427",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "statistics = df_indoor.groupby('sensor_id_floor_sho').agg({\n",
    "    'temp_d': ['mean', 'median', 'max', 'min', 'std']\n",
    "})\n",
    "\n",
    "# Columns to store stats values\n",
    "statistics.columns = ['Mean', 'Median', 'Max', 'Min', 'Std']\n",
    "\n",
    "# Display as table format\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "243ec420-6b36-4e34-9a9e-5910c552a4e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The 'mean', 'median' and 'Max' seem to similar across all the sensors in 3rd and 4th floor. On the other hand, 'Min' value for sensors indicates some outliers. For example, 'ENKZYW001882_3F' has value as low as 11.5, 'ENKZYW001792_3F' has 15.9 and there are a couple in 17s, 18s and 19s. As far as 'Standard deviation' is concerned, for most of the censors the value revolves around 1 except a few sensor like 'ENKZYW001882_3F' where the value is as high as 1.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=('Median','Max','Min Temperature', 'Standard Deviation'))\n",
    "\n",
    "# Add trace for 'Median' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Median'], name='Median Temperature'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add trace for 'Max' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Max'], name='Max Temperature'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add trace for 'Min' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Min'], name='Min Temperature'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add trace for 'Std'\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Std'], name='Standard Deviation'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=700, width=1000, title_text=\"Temperature Statistics by sensor_id_floor_sho\")\n",
    "\n",
    "#fig.update_layout(xaxis={'tickangle': 45})\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "column_name = 'temp_d'\n",
    "temp_threhold = 21\n",
    "indoor_combined_single_plot(df_indoor,column_name,temp_threhold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On looking up all the sensors together including both 3rd-floor and 4th-floor sensors, the overall trend seems to be flat. There are a couple of sensors that are deviating from normal majorly in two instances. One around Jan 29 - Jan 30 and the other around Feb 3 - Feb 4. There are a couple of minor ones, for example, one around Feb 11-13. We'll investigate them further in the later stage.\n",
    "\n",
    "The plot also shows gaps for the sensors where data is missing e.g. ENKZYW001856_3F and ENKZYW001804_3F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a61df865-dc80-4c66-8031-94ec28013436",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.1.3 Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'temp_d'\n",
    "duration ='time_5'\n",
    "sesonality(df_indoor_2,column_name,duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily seasonality can be seen in both the floors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 'Date'\n",
    "sesonality(df_indoor_2,column_name,duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weekly seasonality, the data is quite limited. Still, there are a few observation:\n",
    "\n",
    "1. 3rd Floor: Not a clear pattern of weekly seasonality.\n",
    "\n",
    "2. 4th Floor: Some sort of pattern is displayed where the sensors are showing downward trend on weekends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'temp_d'\n",
    "correlation_matrix = correlation(df_indoor_2,column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48b75547-6aac-4b05-a3fd-0a6d3d15053a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Display sensors which are strongly correlated to each other\n",
    "strong_correlation_list(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used a threshold of 0.5 for analysing the correlation:\n",
    "\n",
    "Based on the correlation results,\n",
    "\n",
    "1. Are there any sensors on the 3rd floor that are correlated to sensors on the 4th floor as far as 'desk temperature' is concerned?\n",
    "\n",
    "In most of the cases, the sesnors of the 3rd floor are not strongly correlated to the sesnors of the 4th floor except in two cases which are '1856_3F' and '1882_3F'. They are positively correlated to '1935_4F' with values more than 0.69. Interestingly, looking at the sensor location, the positions of these sensors are at a similar point (area) on their respective floors.\n",
    "\n",
    "2. What are the pairs of sensors which are strongly correlated to each other? Are these pairs mounted next (near) to each other?\n",
    "\n",
    "On the 3rd floor, each sensor is highly correlated to each other except '1856_3F'. It is correlated to '1882_3F' which is mounted near to it. Interestingly, the other sensor i.e. 1848_3F', which seems to be in a similar distance with '1856_3F', is not as highly correlated as '1882_3F'.\n",
    "\n",
    "On the 4th floor as well, each sensor is highly correlated to each other except 'temp_d_1900_4F'. It is highly correlated to the sensors which are at the right and left of the sensor i.e. temp_d_1925_4F and temp_d_1888_4F.\n",
    "\n",
    "The correlation can help us to understand the behavior of one sensor concerning others.\n",
    "\n",
    "Note: For more details, refer to the last output and heat map which are displayed just above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Indoor Temp - Individual Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Trend and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'temp_d'\n",
    "temp_threhold = 21\n",
    "indoor_combined_different_floor_plot(df_indoor,column_name,temp_threhold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots provide more details when looked at separately. Let's discuss the sensors on the 3rd floor first:\n",
    "\n",
    "Overall it looks alright other than some cases where the values seem to be anomalous. \n",
    "\n",
    "1. Feb 2- Feb 3: All the sensors showed a downward trend especially 'ENKZYW001882_3F' which reached around 11Â°C-13Â°C and 'ENKZYW001792_3F' which reached around 16-18. All other sensors, whose data is available, also crossed the temperature threshold from the Feb 2 evening to the next day's morning around 10 AM. \n",
    "\n",
    "2. Feb 5 (2 AM - 1 PM): All the sensors showed a downward trend and crossed the temperature threshold.\n",
    "\n",
    "3. Feb 7 - 8: Both 'ENKZYW001882_3F' and 'ENKZYW001848_3F' were out of the threshold most of the time. 'ENKZYW001882_3F' also showed high fluctuation around 11-5 on Feb 7. Interestingly both the sesnors are placed on the other side of the floor.\n",
    "\n",
    "4. Feb 13 -14:  All the sensors showed an upward trend and some sensors reached their max value e.g. 'ENKZYW001882_3F' touch around 26.\n",
    "\n",
    "5. Feb 16 -19:  'ENKZYW001856_3F' fell sharply from 25Â°C to 21Â°C and remained around 21Â°C till the end.\n",
    "\n",
    "All the sensors showed an upward trend and some sensors reached their max value e.g. 'ENKZYW001882_3F' touching around 26.\n",
    "\n",
    "Let's discuss the sensors on the 4th floor:\n",
    "\n",
    "The fluctuations of fourth-floor sensors look higher, especially for sensors 'ENKZYW001958_4F' and 'ENKZYW001935_4F'. We can also see some anomalous cases as well:\n",
    "\n",
    "1. Jan 29 - Jan 30: All the sensors showed a downward trend and crossed the temperature threshold. \n",
    "\n",
    "2. Feb 1 - Feb 4: 'ENKZYW001958_4F' was below the threshold in this period and showed high fluctuation.\n",
    "\n",
    "3. Feb 7: Earning morning, Feb 7 all the sensors went downward, with 'ENKZYW001900_4F' and 'ENKZYW001925_4F' crossing the threshold. Only 'ENKZYW001884_4F' went upwards which is unusual as it highly correlated with sensors '1888_4F', '1883_4F',    '1935_4F', and '1958_4F'.\n",
    "\n",
    "4. Feb 18 - Feb 19: All the sensors showed a downward trend and some sensors liek'ENKZYW001958_4F','' ENKZYW001883_4F', etc. crossed the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the outdoor temperature is anyhow correlated to any of the indoor temperatures provided by the sensors on the 3rd and 4th floors. It could be possible that it can provide some effect on the sensor values, especially the abnormal behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Indoor temp with outdoor data for both floors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indoor_3 = df_indoor_2.copy()\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df_indoor_3 = df_indoor_3.pivot_table(index='documentTime', columns='sensor_id_floor_sho', values=['temp_d']).reset_index()\n",
    "\n",
    "# Flatten the multi-index column names\n",
    "pivot_df_indoor_3.columns = ['_'.join(col).strip() for col in pivot_df_indoor_3.columns.values]\n",
    "\n",
    "#Resample it to 1 hour\n",
    "pivot_df_indoor_3_r = pivot_df_indoor_3.resample('1H', on='documentTime_').first()\n",
    "pivot_df_indoor_3_r = pivot_df_indoor_3_r.rename(columns={'documentTime_':'documentTime'})\n",
    "\n",
    "# Merge df1_resampled with df2\n",
    "merged_df = pd.merge(df_outdoor, pivot_df_indoor_3_r, on='documentTime', how='inner')\n",
    "\n",
    "#merged_df= merged_df.drop(columns={'level_0','documentTime'})\n",
    "merged_df_2= merged_df.drop(columns={'documentTime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = merged_df_2.corr()\n",
    "correlation_matrix[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Matrix, we can say that the Outdoor weather is weekly related to the temperature of indoor for both floors. For outdoor tempearture, the best value is 0.44 with 'temp_d_1848_3F' which is sort of week to moderate. We can also confirm this observation with plotting outdoor parameter with indoor tempearture value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in merged_df\n",
    "columns_in_out= list(merged_df.columns)\n",
    "columns_in_out.remove('documentTime')\n",
    "\n",
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns_in_out:\n",
    "    fig.add_trace(go.Scatter(x=merged_df['documentTime'], y=merged_df[column], mode='lines', name=column))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title= 'Line Plot with all temperature sensor with Outdoor parameters',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title= column_name)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there is one common area where the outdoor temperature is going upwards on the higher side and all the indoor senor temperature data from the 3rd floor is going downward, there is no conclusive evidence as it showed different behavior next time. So, the role of outdoor temperature on indoor data semms not significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(merged_df_2), columns=merged_df_2.columns,index=merged_df_2.index)\n",
    "\n",
    "df_normalized['documentTime'] = df_outdoor['documentTime']\n",
    "\n",
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns_in_out:\n",
    "    fig.add_trace(go.Scatter(x=df_normalized['documentTime'], y=df_normalized[column], mode='lines', name=column))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title= 'Normalized Line Plot with all temperature sensor with Outdoor parameters',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title= column_name)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Outliers - 3rd Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already observed some anomalous bevahious in Trend line plot (Trend Section). This section will give more details in terms of numbers and dates for each sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly boxplot\n",
    "fig = px.box(df_indoor[df_indoor['Floor']=='3F'], x='sensor_id', y='temp_d')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='3F'],'sensor_id','temp_d',1.5,21,'outlier')\n",
    "\n",
    "sensor_type = \"Desk Temperature Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By \"working condition\" Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='3F'],'sensor_id','temp_d',1.5,21,'condition')\n",
    "\n",
    "sensor_type = \"Desk Temperature less_than_21\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Outliers - 4th Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly boxplot\n",
    "fig = px.box(df_indoor[df_indoor['Floor']=='4F'], x='sensor_id', y='temp_d')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='4F'],'sensor_id','temp_d',1.5,21,'outlier')\n",
    "\n",
    "sensor_type = \"Desk Temperature Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By \"working condition\" Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='4F'],'sensor_id','temp_d',1.5,21,'condition')\n",
    "\n",
    "sensor_type = \"Desk Temperature less_than_21\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at observing the outliers calculated using IQR or Box plot for both floors, the count for common dates is quite less on comparing the 3rd floor to the 4th floor. It suggests that the incidents which have been observed are not connected. It also corroborates the fact that most of the sensors on the third floor are not correlated to the sensors on the fourth floor.\n",
    "\n",
    "In the next sections i.e. Humidity and CO2, we'll also try to find if there are in any similarities in the abnormal values as per indoor temperature data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data Exploration - Humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Combined Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Statistics of Humidity for both floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d6d8266-1429-4066-ab21-b74636178681",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "statistics = df_indoor.groupby('sensor_id_floor_sho').agg({\n",
    "    'humidity': ['mean', 'median', 'max', 'min', 'std']\n",
    "})\n",
    "\n",
    "# Columns to store ststs values\n",
    "statistics.columns = ['Mean', 'Median', 'Max', 'Min', 'Std']\n",
    "\n",
    "# Display as table format\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=('Median','Max','Min', 'Standard Deviation'))\n",
    "\n",
    "# Add trace for 'Median' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Median'], name='Median Humidity'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add trace for 'Max' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Max'], name='Max Humidity'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add trace for 'Min' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Min'], name='Min Humidity'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add trace for 'Std'\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Std'], name='Standard Deviation'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=700, width=1000, title_text=\"Humidity Statistics by sensor_id_floor_sho\")\n",
    "\n",
    "#fig.update_layout(xaxis={'tickangle': 45})\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.2 Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fca32053-b153-41d3-bf59-ad7d23ec6f91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each unique type and plot its line\n",
    "for type_val in df_indoor['sensor_id_floor_lon'].unique():\n",
    "    df_type = df_indoor[(df_indoor['sensor_id_floor_lon'] == type_val)]\n",
    "    fig.add_trace(go.Scatter(x=df_type['documentTime'], y=df_type['humidity'], mode='lines', name=type_val))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Line Plot of Temperature by Sensor',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title='humidity')\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On looking up all the sensors together including both 3rd-floor and 4th-floor sensors, the overall trend seems to be flat. However in the first half (before Feb 5) and From Feb 10 - Feb 19, there is a increasing trend.\n",
    "\n",
    "The sensors looks highly correlated to each other. It will be confirmed using correlation matrix.\n",
    "\n",
    "The plot also shows gaps for the sensors where data is missing e.g. ENKZYW001856_3F and ENKZYW001804_3F.\n",
    "\n",
    "There are a couple of sensors that are deviating from normal majorly around Feb 2 - Feb 4. It will be investigated later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.3 Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'humidity'\n",
    "duration ='time_5'\n",
    "sesonality(df_indoor_2,column_name,duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daily seasonality can be seen in both the floors. On 4th Floor, it looks a bit stronger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 'Date'\n",
    "sesonality(df_indoor_2,column_name,duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weekly seasnality, the data is quite limited. On both the floors, not a clear pattern of weekly seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.4 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = correlation(df_indoor_2,column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_plot(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sensors which are strongly correlated to each other\n",
    "strong_correlation_list(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used threshold of 0.5 for analysing the correlation:\n",
    "\n",
    "Based on the correlation results, we can clearly see that all the sensors are strongly correlated to each other as far as 'humidity' is concerned except 1856_3F. One can thought, it could be possible due to its location but on the 4th floor, 1935_4F is also highly correlated with almost all the sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Humidity - Individual Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Trend and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'humidity'\n",
    "temp_threhold = 20\n",
    "indoor_combined_different_floor_plot(df_indoor,column_name,temp_threhold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plots provide more details when looked at separtly. There is no instance of a value crossing the given threshold.\n",
    "\n",
    "Based on the plots the only anomalous reason seems to be in the third floor around the Feb2 - Feb4 period. All the values are going in upward direction with some sensors going really high e.g. 1882_3F and '1792_3F'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the outdoor temperature is anyhow correlated to any of the indoor temperatures provided by the sensors on the 3rd and 4th floors. It could be possible that it can provide some effect on the sensor values, especially the abnormal behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation for Humidity with outdoor data for both floors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indoor_3 = df_indoor_2.copy()\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df_indoor_3 = df_indoor_3.pivot_table(index='documentTime', columns='sensor_id_floor_sho', values=['humidity']).reset_index()\n",
    "\n",
    "# Flatten the multi-index column names\n",
    "pivot_df_indoor_3.columns = ['_'.join(col).strip() for col in pivot_df_indoor_3.columns.values]\n",
    "\n",
    "#Resample it to 1 hour\n",
    "pivot_df_indoor_3_r = pivot_df_indoor_3.resample('1H', on='documentTime_').first()\n",
    "pivot_df_indoor_3_r = pivot_df_indoor_3_r.rename(columns={'documentTime_':'documentTime'})\n",
    "\n",
    "# Merge df1_resampled with df2\n",
    "merged_df = pd.merge(df_outdoor, pivot_df_indoor_3_r, on='documentTime', how='inner')\n",
    "\n",
    "#merged_df= merged_df.drop(columns={'level_0','documentTime'})\n",
    "merged_df_2= merged_df.drop(columns={'documentTime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = merged_df_2.corr()\n",
    "correlation_matrix[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The external temperature seems to be strongly correlated to all the sensors except 1856_3F as far as indoor 'humidity' values are concerned. On the other hand, external humidity is not at all correlated. We can also confirm this observation with plotting outdoor parameter with indoor humidity value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in merged_df\n",
    "columns_in_out= list(merged_df.columns)\n",
    "columns_in_out.remove('documentTime')\n",
    "\n",
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns_in_out:\n",
    "    fig.add_trace(go.Scatter(x=merged_df['documentTime'], y=merged_df[column], mode='lines', name=column))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title= 'Line Plot with all Humidity sensor with Outdoor parameters',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title= column_name)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(merged_df_2), columns=merged_df_2.columns,index=merged_df_2.index)\n",
    "\n",
    "df_normalized['documentTime'] = df_outdoor['documentTime']\n",
    "\n",
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns_in_out:\n",
    "    fig.add_trace(go.Scatter(x=df_normalized['documentTime'], y=df_normalized[column], mode='lines', name=column))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title= 'Normalized Line Plot with all Humidity sensor with Outdoor parameters',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title= column_name)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that when the temperature goes up the humidity value also goes up and the anomalous region on the third floor around the Feb2 - Feb4 period could be related to the rise of temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Outliers Humidity - 3rd Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already observed some anomalous bevahious in Trend line plot (Trend Section). This section will give more details in terms of numbers and dates for each sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly boxplot\n",
    "fig = px.box(df_indoor[df_indoor['Floor']=='3F'], x='sensor_id', y='humidity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='3F'],'sensor_id','humidity',1.5,20,'outlier')\n",
    "\n",
    "sensor_type = \"Humidity Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have no case for values crossing condition threshold, we'll not be plotting \"Outlier By 'working condition' Threshold\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Outliers Humidity - 4th Floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly boxplot\n",
    "fig = px.box(df_indoor[df_indoor['Floor']=='4F'], x='sensor_id', y='humidity')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no outlier displayed in this cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation/Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed this on the 3rd floor for temperature values:\n",
    "\n",
    "Feb 2- Feb 3: All the sensors showed downward trend especially 'ENKZYW001882_3F' which reached around 11Â°C-13Â°C and 'ENKZYW001792_3F' which reached around 16-18. All other sensors, whose data is available, also crossed the temperature threshold from Feb 2 evening to next day morning around 10 AM. \n",
    "\n",
    "And if I look at humidity plot for 3rd floor:\n",
    " \n",
    "Around Feb2 - Feb4 period. All the values are going in upward direction with some sensors going really high e.g. 'ENKZYW001882_3F and 'ENKZYW001792_3F'.\n",
    "\n",
    "So, it is highly likely that there is connection between these two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data Exploration - Co2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Combined Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Statistics of Co2 for both floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11ebbafe-e682-4d02-bda2-242a2ff6c753",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Calculate statistics\n",
    "statistics = df_indoor.groupby('sensor_id_floor_sho').agg({\n",
    "    'co2': ['mean', 'median', 'max', 'min', 'std']\n",
    "})\n",
    "\n",
    "# Columns to store ststs values\n",
    "statistics.columns = ['Mean', 'Median', 'Max', 'Min', 'Std']\n",
    "\n",
    "# Display as table format\n",
    "print(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=('Median','Max','Min', 'Standard Deviation'))\n",
    "\n",
    "# Add trace for 'Median' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Median'], name='Median Humidity'),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add trace for 'Max' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Max'], name='Max Humidity'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Add trace for 'Min' temperature\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Min'], name='Min Humidity'),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add trace for 'Std'\n",
    "fig.add_trace(\n",
    "    go.Bar(x=statistics.index, y=statistics['Std'], name='Standard Deviation'),\n",
    "    row=2, col=2\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(height=700, width=1000, title_text=\"Humidity Statistics by sensor_id_floor_sho\")\n",
    "\n",
    "#fig.update_layout(xaxis={'tickangle': 45})\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "baae9ee4-4b55-4619-800b-de08c24b72f5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each unique type and plot its line\n",
    "for type_val in df_indoor['sensor_id_floor_lon'].unique():\n",
    "    df_type = df_indoor[(df_indoor['sensor_id_floor_lon'] == type_val)]\n",
    "    fig.add_trace(go.Scatter(x=df_type['documentTime'], y=df_type['co2'], mode='lines', name=type_val))\n",
    "    \n",
    "# Add a flat dotted line of y = 1000\n",
    "fig.add_trace(go.Scatter(x=[min(df_indoor['documentTime']), max(df_indoor['documentTime'])], y=[1000, 1000],\n",
    "                         mode='lines', name='y=100', line=dict(dash='dot', color='black', width=2)))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Line Plot of Temperature by Sensor',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title='co2')\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On looking up all the sensors together including both 3rd-floor and 4th-floor sensors, the overall trend seems to be quite flactuating like sine wave unlike indoor and humidity plots. It is indicating some seasonality.\n",
    "\n",
    "The sensors looks highly correlated to each other. It will be confirmed using correlation matrix.\n",
    "\n",
    "The plot also shows gaps for the sensors where data is missing e.g. ENKZYW001856_3F and ENKZYW001804_3F.\n",
    "\n",
    "There are a couple of sensors that are crossing condition threshold. It will be investigated later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.3 Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'co2'\n",
    "duration ='time_5'\n",
    "sesonality(df_indoor_2,column_name,duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Co2 is showing higher daily seasonality for both the floors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 'Date'\n",
    "sesonality(df_indoor_2,column_name,duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Co2 is showing higher weekly seasonality for both the floors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca8bdaa9-1a63-4bc2-859f-86617bd12cad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.1.4 Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61e8c4d6-3389-45f0-a64b-274e0cd5866c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "correlation_matrix = correlation(df_indoor_2,column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b3eb0a-3b37-424c-a9c6-eebc5c42f15d",
     "showTitle": false,
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlation_plot(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sensors which are strongly correlated to each other\n",
    "strong_correlation_list(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used threshold of 0.5 for analysing the correlation:\n",
    "\n",
    "As expected, Based on the correlation results, we can clearly see that all the sensors are strongly correlated to each other as far as 'Co2' is concerned except 1856_3F."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Co2 - Individual Floors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "03d89d57-2fb8-4e21-a92e-785d91bea338",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.2.1 Trend and observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'co2'\n",
    "temp_threhold = 1000\n",
    "indoor_combined_different_floor_plot(df_indoor,column_name,temp_threhold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86152ab8-7b3c-4aaf-9c2b-8b988c8d6d81",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "The plots provide more details when looked at separately. \n",
    "\n",
    "Based on the plots the main anomalous reason seems to be around January 29th when the trend of all the sensors on the 3rd floor looks quite identical to the sensors on the 4th floor. The values are going up in the morning of the 29th around 8-9 AM and crossing the threshold to reach quite a high value of 1200-1300. It started going downward around 2-3 PM.\n",
    "\n",
    "Apart from this, third-floor behavior seems reasonable. However, on the fourth floor, there are a couple of incidents where values are going above the threshold. For example, around Feb 7 and Feb 8, 1935_4, F1900_4F and 1888_4F are crossing the threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7019551f-1c71-461b-9bb3-3ed51d1069b2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's see if the outdoor variables are anyhow correlated to any of the co2 values provided by the sensors on the 3rd and 4th floors. It could be possible that it can have some effect on the sensor values, especially the abnormal behaviors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3084c20b-9816-46ef-beaa-498597175faa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Data Preparation of Co2 with outdoor data for both floors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indoor_3 = df_indoor_2.copy()\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df_indoor_3 = df_indoor_3.pivot_table(index='documentTime', columns='sensor_id_floor_sho', values=['co2']).reset_index()\n",
    "\n",
    "# Flatten the multi-index column names\n",
    "pivot_df_indoor_3.columns = ['_'.join(col).strip() for col in pivot_df_indoor_3.columns.values]\n",
    "\n",
    "#Resample it to 1 hour\n",
    "pivot_df_indoor_3_r = pivot_df_indoor_3.resample('1H', on='documentTime_').first()\n",
    "pivot_df_indoor_3_r = pivot_df_indoor_3_r.rename(columns={'documentTime_':'documentTime'})\n",
    "\n",
    "# Merge df1_resampled with df2\n",
    "merged_df = pd.merge(df_outdoor, pivot_df_indoor_3_r, on='documentTime', how='inner')\n",
    "\n",
    "#merged_df= merged_df.drop(columns={'level_0','documentTime'})\n",
    "merged_df_2= merged_df.drop(columns={'documentTime'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = merged_df_2.corr()\n",
    "correlation_matrix[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the Matrix, we can say that the Outdoor weather is weekly related to the co2 of indoor for both floors. We can also confirm this observation with plotting outdoor parameter with indoor tempearture value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns in merged_df\n",
    "columns_in_out= list(merged_df.columns)\n",
    "columns_in_out.remove('documentTime')\n",
    "\n",
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns_in_out:\n",
    "    fig.add_trace(go.Scatter(x=merged_df['documentTime'], y=merged_df[column], mode='lines', name=column))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title= 'Line Plot with all Humidity sensor with Outdoor parameters',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title= column_name)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is not giving much idea due to scale difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Normalize the columns\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(merged_df_2), columns=merged_df_2.columns,index=merged_df_2.index)\n",
    "\n",
    "df_normalized['documentTime'] = df_outdoor['documentTime']\n",
    "\n",
    "# Plotly line plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate over each column\n",
    "for column in columns_in_out:\n",
    "    fig.add_trace(go.Scatter(x=df_normalized['documentTime'], y=df_normalized[column], mode='lines', name=column))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title= 'Normalized Line Plot with all Humidity sensor with Outdoor parameters',\n",
    "                  xaxis_title='documentTime',\n",
    "                  yaxis_title= column_name)\n",
    "\n",
    "# Show plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the anomalous region of January 29th when the values went up crossing the threshold to reach quite a high value of 1200-1300, the outdoor temperature is going upwards from the lowest ever higher side. However, the pattern looks not be repeating. So, the role of outdoor temperature on indoor data seems not significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89a8368f-44dc-4164-ad3e-11318dfaa89a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 7.2.2 Outliers Co2 - 3rd Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a0a62fb7-9db1-4806-b222-9e01209e05e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Plotly boxplot\n",
    "fig = px.box(df_indoor[df_indoor['Floor']=='3F'], x='sensor_id', y='co2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='3F'],'sensor_id','co2',1.5,1000,'outlier')\n",
    "\n",
    "sensor_type = \"Co2 Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By \"working condition\" Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='3F'],'sensor_id','co2',1.5,1000,'condition')\n",
    "\n",
    "sensor_type = \"Co2 Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.3 Outliers Co2 - 4th Floor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By interquartile range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly boxplot\n",
    "fig = px.box(df_indoor[df_indoor['Floor']=='4F'], x='sensor_id', y='co2')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='4F'],'sensor_id','co2',1.5,1000,'outlier')\n",
    "\n",
    "sensor_type = \"Co2 Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By \"working condition\" Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers,outliers_count_per_sensor_per_day=detect_outliers(df_indoor[df_indoor['Floor']=='4F'],'sensor_id','co2',1.5,1000,'condition')\n",
    "\n",
    "sensor_type = \"Co2 Outliers\"\n",
    "outlier_plot(outliers_count_per_sensor_per_day, sensor_type)\n",
    "\n",
    "# Calculate the count of each date\n",
    "date_outliers_count1 = outliers_count_per_sensor_per_day.groupby(['sensor_id', 'date'])['outliers_count'].sum()\n",
    "date_outliers_count2 = outliers_count_per_sensor_per_day.groupby(['date', 'sensor_id'])['outliers_count'].sum()\n",
    "print(\"-----By Sensor------\")\n",
    "print(\"\\n\")\n",
    "print(date_outliers_count1)\n",
    "print(\"\\n\")\n",
    "print(\"-------By Date-----\")\n",
    "print(date_outliers_count2)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Untitled (2)",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
